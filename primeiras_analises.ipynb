{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "total_cpus = os.cpu_count()\n",
    "\n",
    "# Calculate 80% of the available CPUs\n",
    "num_threads = int(total_cpus * 0.8)\n",
    "\n",
    "print(f'Number of threads: {num_threads}.')\n",
    "\n",
    "torch.set_num_threads(num_threads)\n",
    "torch.set_num_interop_threads(num_threads)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf \n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torch.nn import Module\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Adjust to your MLflow server URI\n",
    "mlflow.set_experiment(\"Stock Prediction\")\n",
    "\n",
    "\n",
    "    \n",
    "class StockPrediction():\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = None\n",
    "        print(f'Torch running in device: {self.device}')\n",
    "\n",
    "    def load_yfinance_data(self, enterprise, start_date, end_date):\n",
    "        yf_df = yf.download(enterprise, start=start_date, end=end_date).reset_index()\n",
    "\n",
    "        ds = duckdb.sql(f\"\"\"\n",
    "            DROP TABLE IF EXISTS finance;\n",
    "            CREATE TABLE finance AS ( \n",
    "                SELECT\n",
    "                \"('Date', '')\" as dt_time\n",
    "                ,date_trunc('day', \"('Date', '')\") as dt\n",
    "                ,\"('Adj Close', '{enterprise}')\" as adj_close\n",
    "                ,\"('Close', '{enterprise}')\" as close\n",
    "                ,\"('High', '{enterprise}')\" as high\n",
    "                ,\"('Low', '{enterprise}')\" as low\n",
    "                ,\"('Open', '{enterprise}')\" as open\n",
    "                ,\"('Volume', '{enterprise}')\" as volume\n",
    "\n",
    "                FROM yf_df\n",
    "            )\n",
    "            \"\"\")\n",
    "        \n",
    "    def get_yfinance_dataset(self):\n",
    "        finance_dataset = duckdb.sql(\"\"\"\n",
    "            SELECT         \n",
    "                * \n",
    "            FROM finance\n",
    "                \"\"\")    \n",
    "        \n",
    "\n",
    "        #finance_dataset.show()\n",
    "        \n",
    "        return finance_dataset.df()\n",
    "    \n",
    "    def get_train_n_test(self, test_size = 0.65):\n",
    "        yfinance_dataset = self.get_yfinance_dataset()\n",
    "\n",
    "        timeseries = yfinance_dataset[[\"adj_close\"]].values.astype('float32')\n",
    "        dt_time = yfinance_dataset['dt']\n",
    "\n",
    "        train_size = int(len(timeseries) * test_size)\n",
    "        test_size = len(timeseries) - train_size\n",
    "        train, test = timeseries[:train_size], timeseries[train_size:]\n",
    "        dt_train, dt_test = dt_time[:train_size], dt_time[train_size:]\n",
    "\n",
    "        return dt_train, train, dt_test, test\n",
    "    \n",
    "    def plot_yfinance_dataset(self, plot_test=False):    \n",
    "        dt_train, train, dt_test, test = self.get_train_n_test()\n",
    "\n",
    "        \n",
    "        if (plot_test):\n",
    "            dt_time = dt_test\n",
    "            timeseries = test\n",
    "        else:\n",
    "            dt_time = dt_train\n",
    "            timeseries = train            \n",
    "\n",
    "\n",
    "        plt.plot(dt_time, timeseries)\n",
    "        plt.grid(True)\n",
    "        plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()         \n",
    "\n",
    "\n",
    "    def create_torch_dataset(self, dataset, lookback):\n",
    "        \"\"\"Transform a time series into a prediction dataset\n",
    "        \n",
    "        Args:\n",
    "            dataset: A numpy array of time series, first dimension is the time steps\n",
    "            lookback: Size of window for prediction\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(dataset)-lookback):\n",
    "            feature = dataset[i:i+lookback]\n",
    "            target = dataset[i+1:i+lookback+1]\n",
    "            X.append(feature)\n",
    "            y.append(target)\n",
    "        return torch.tensor(X).to(self.device), torch.tensor(y).to(self.device)\n",
    "    \n",
    "    def get_torch_train_n_test(self, test_percentage = 0.65, lookback = 4):\n",
    "        _x_train, _y_train, _x_test, _y_test = self.get_train_n_test(0.65)\n",
    "        \n",
    "        x_train, y_train = self.create_torch_dataset(_y_train, lookback=lookback)\n",
    "        x_test, y_test = self.create_torch_dataset(_y_test, lookback=lookback) \n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    def train_model(self, model: Module, x_train, y_train, x_test, y_test, n_epochs=100, weight_decay=1e-4, log_frequency=10, prefix=\"prf\"):\n",
    "            self.model = model.to(self.device)\n",
    "\n",
    "            optimizer = optim.Adam(self.model.parameters(), weight_decay=weight_decay)\n",
    "            loss_fn = nn.MSELoss()\n",
    "            loader = data.DataLoader(data.TensorDataset(x_train, y_train), shuffle=True, batch_size=64)\n",
    "\n",
    "            run_timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            # Start an MLflow run\n",
    "            with mlflow.start_run(run_name=f\"StockPrediction_{prefix}_{run_timestamp}\", nested=False):\n",
    "                # Log model parameters\n",
    "                mlflow.log_param(\"n_epochs\", n_epochs)\n",
    "                mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "                \n",
    "                model_config = {\n",
    "                    \"input_size\": 1,\n",
    "                    \"hidden_size\": model.lstm.hidden_size,\n",
    "                    \"num_layers\": model.lstm.num_layers,\n",
    "                    \"batch_first\": model.lstm.batch_first,\n",
    "                    \"dropout\": model.lstm.dropout if hasattr(model.lstm, \"dropout\") else 0,\n",
    "                    \"linear_output_size\": model.linear.out_features,\n",
    "                    \"model_activator\": model.activation\n",
    "                }\n",
    "\n",
    "                mlflow.log_params(model_config)\n",
    "\n",
    "                for epoch in range(n_epochs):\n",
    "                    self.model.train()\n",
    "                    for X_batch, y_batch in loader:\n",
    "                        X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                        y_pred = self.model(X_batch)\n",
    "                        loss = loss_fn(y_pred, y_batch)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # Validation\n",
    "                    if (epoch % log_frequency == 0) or (epoch == n_epochs - 1):  # Log metrics every 10 epochs\n",
    "                        self.model.eval()\n",
    "                        with torch.no_grad():\n",
    "                            y_pred_train = self.model(x_train)\n",
    "                            y_pred_test = self.model(x_test)\n",
    "\n",
    "                            # Calculate metrics\n",
    "                            train_loss = loss_fn(y_pred_train, y_train)\n",
    "                            train_rmse = torch.sqrt(train_loss).item()\n",
    "                            train_mae = torch.mean(torch.abs(y_train - y_pred_train)).item()\n",
    "                            train_mape = (torch.mean(torch.abs((y_train - y_pred_train) / y_train)) * 100).item()\n",
    "\n",
    "                            test_loss = loss_fn(y_pred_test, y_test)\n",
    "                            test_rmse = torch.sqrt(test_loss).item()\n",
    "                            test_mae = torch.mean(torch.abs(y_test - y_pred_test)).item()\n",
    "                            test_mape = (torch.mean(torch.abs((y_test - y_pred_test) / y_test)) * 100).item()\n",
    "\n",
    "                        # Log metrics\n",
    "                        mlflow.log_metric(\"train_rmse\", train_rmse, step=epoch)\n",
    "                        mlflow.log_metric(\"train_mae\", train_mae, step=epoch)\n",
    "                        mlflow.log_metric(\"train_mape\", train_mape, step=epoch)\n",
    "                        mlflow.log_metric(\"test_rmse\", test_rmse, step=epoch)\n",
    "                        mlflow.log_metric(\"test_mae\", test_mae, step=epoch)\n",
    "                        mlflow.log_metric(\"test_mape\", test_mape, step=epoch)\n",
    "\n",
    "                        # Print metrics\n",
    "                        print(f\"Epoch {epoch}:\")\n",
    "                        print(f\"  Train -> MAE: {train_mae:.4f}, RMSE: {train_rmse:.4f}, MAPE: {train_mape:.2f}%\")\n",
    "                        print(f\"  Test  -> MAE: {test_mae:.4f}, RMSE: {test_rmse:.4f}, MAPE: {test_mape:.2f}%\")\n",
    "\n",
    "                # Log the model at the end of training\n",
    "                mlflow.pytorch.log_model(self.model, \"model\")\n",
    "\n",
    "    def test_model(self, model: Module, x_train, x_test, lookback=4):            \n",
    "        yfinance_dataset = self.get_yfinance_dataset()\n",
    "        test_size = 0.65\n",
    "\n",
    "        timeseries = yfinance_dataset[[\"adj_close\"]].values.astype('float32')\n",
    "        train_size = int(len(timeseries) * test_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            train_plot = np.ones((len(timeseries), 1)) * np.nan\n",
    "            test_plot = np.ones((len(timeseries), 1)) * np.nan\n",
    "\n",
    "            # Move tensors to CPU before converting to NumPy\n",
    "            y_pred_train = model(x_train).cpu().numpy()[:, -1, :]\n",
    "            y_pred_test = model(x_test).cpu().numpy()[:, -1, :]\n",
    "            \n",
    "            train_plot[lookback:lookback + len(y_pred_train), 0] = y_pred_train[:, 0]\n",
    "            test_plot[train_size + lookback:train_size + lookback + len(y_pred_test), 0] = y_pred_test[:, 0]\n",
    "\n",
    "            plt.plot(timeseries, label=\"Actual\")\n",
    "            plt.plot(train_plot, c='r', label=\"Train Predictions\")\n",
    "            plt.plot(test_plot, c='g', label=\"Test Predictions\")\n",
    "            plt.legend()\n",
    "            plt.savefig(\"predictions_plot.png\")  # Save the plot\n",
    "\n",
    "            # Log plot as an artifact\n",
    "            mlflow.log_artifact(\"predictions_plot.png\")\n",
    "            plt.show()\n",
    "\n",
    "    def load_model_from_mlflow(self, model_uri):\n",
    "        \"\"\"\n",
    "        Load a model from MLflow.\n",
    "\n",
    "        Args:\n",
    "            model_uri (str): The URI of the model in MLflow.\n",
    "        \"\"\"\n",
    "        print(f\"Loading model from MLflow at {model_uri}...\")\n",
    "        self.model = mlflow.pytorch.load_model(model_uri).to(self.device)\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "    def execute_model(self, input_data):\n",
    "        \"\"\"\n",
    "        Execute the loaded model on new data.\n",
    "\n",
    "        Args:\n",
    "            input_data (torch.Tensor or numpy.ndarray): Input data for the model.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Model predictions.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No model loaded. Please load a model first using 'load_model_from_mlflow'.\")\n",
    "\n",
    "        # Convert input data to a torch.Tensor if it is a numpy array\n",
    "        if isinstance(input_data, np.ndarray):\n",
    "            input_data = torch.tensor(input_data, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(input_data)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_and_plot(self, input_data, correct_values):\n",
    "        \"\"\"\n",
    "        Predict with the loaded model, plot predictions against correct values, and calculate metrics.\n",
    "\n",
    "        Args:\n",
    "            input_data (torch.Tensor): Input values for the model.\n",
    "            correct_values (torch.Tensor): Correct (ground truth) values to compare against predictions.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing calculated metrics.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No model loaded. Please load a model first using 'load_model_from_mlflow'.\")\n",
    "\n",
    "        self.model.eval()\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Use execute_model for predictions\n",
    "            predictions = self.execute_model(input_data).squeeze()\n",
    "            correct_values = correct_values.squeeze()\n",
    "\n",
    "            # Take only the last value of each sequence for comparison\n",
    "            predictions = predictions[:, -1]  # Last column of predictions\n",
    "            correct_values = correct_values[:, -1]  # Last column of correct values\n",
    "\n",
    "            # Debug shapes and sample values\n",
    "            print(\"Debugging Shapes:\")\n",
    "            print(f\"Predictions shape: {predictions.shape}\")\n",
    "            print(f\"Correct values shape: {correct_values.shape}\")\n",
    "            print(\"Sample Predictions:\", predictions[:5])\n",
    "            print(\"Sample Correct Values:\", correct_values[:5])\n",
    "\n",
    "            # Ensure predictions and correct values match in shape\n",
    "            assert predictions.shape == correct_values.shape, (\n",
    "                f\"Mismatch between predictions and correct values. \"\n",
    "                f\"Predictions: {predictions.shape}, Correct: {correct_values.shape}\"\n",
    "            )\n",
    "\n",
    "            # Convert tensors to numpy arrays for plotting\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            correct_values = correct_values.cpu().numpy()\n",
    "\n",
    "            # Calculate metrics\n",
    "            mse_loss = loss_fn(torch.tensor(predictions), torch.tensor(correct_values))\n",
    "            rmse = torch.sqrt(mse_loss).item()\n",
    "            mae = torch.mean(torch.abs(torch.tensor(correct_values) - torch.tensor(predictions))).item()\n",
    "            mape = (torch.mean(torch.abs((torch.tensor(correct_values) - torch.tensor(predictions)) / torch.tensor(correct_values))) * 100).item()\n",
    "\n",
    "            # Prepare the plot\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(correct_values, label=\"Correct Values (Ground Truth)\", color=\"blue\")\n",
    "            plt.plot(predictions, label=\"Predictions\", color=\"red\")\n",
    "            plt.title(\"Model Predictions vs Correct Values\")\n",
    "            plt.xlabel(\"Time Step\")\n",
    "            plt.ylabel(\"Value\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Metrics -> RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%\")\n",
    "\n",
    "        # Return metrics as a dictionary\n",
    "        metrics = {\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'mape': mape\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enterprise = 'GOOGL' \n",
    "start_date = '2024-05-20'  \n",
    "end_date = '2024-11-20' \n",
    "\n",
    "stock_p  = StockPrediction()\n",
    "\n",
    "stock_p.load_yfinance_data(enterprise, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfinance_dataset = stock_p.get_yfinance_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_p.plot_yfinance_dataset(False)\n",
    "stock_p.plot_yfinance_dataset(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "model = StockModel()\n",
    "\n",
    "x_train, y_train, x_test, y_test = stock_p.get_torch_train_n_test()\n",
    "\n",
    "stock_p.train_model(model, x_train, y_train, x_test, y_test, n_epochs = 100000, weight_decay=5e-05, log_frequency=5000, prefix=enterprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_p.test_model(model, x_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste diretos do MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_p = StockPrediction()\n",
    "stock_p.load_model_from_mlflow(\"runs:/4489b98919a94e179e0ccddb469d5bfc/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enterprise = 'GOOGL' \n",
    "start_date = '2022-01-01'  \n",
    "end_date = '2022-12-31' \n",
    "\n",
    "stock_p.load_yfinance_data(enterprise, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 4\n",
    "x_train, y_train, x_test, y_test = stock_p.get_torch_train_n_test(lookback=lookback)\n",
    "\n",
    "# Use predict_and_plot\n",
    "metrics = stock_p.predict_and_plot(x_test, y_test)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Metrics:\", metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_predictions.predictors.stock_predictions import PredictionRunner\n",
    "\n",
    "pred_runner = PredictionRunner(tracking_url=\"http://localhost:5000\", experiment_name=\"Stock Prediction\")\n",
    "\n",
    "pred_runner.torch_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pred_runner.model_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_runner.load_model_mlflow(\"runs:/388a859230994515bf04759f769c7668/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_runner.test_mlflow_model(enterprise = 'GOOGL', start_date = '2022-01-01', end_date = '2022-12-31', lookback = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_runner.predict([0.25,0.256,0.554,0.967])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiap-tech-challenge-04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
